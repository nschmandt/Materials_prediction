{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 5 nodes, the mean f-score is 0.96\n",
      "True Positives: 452, False Positives: 14, False Negatives: 26\n",
      "with 10 nodes, the mean f-score is 0.98\n",
      "True Positives: 459, False Positives: 1, False Negatives: 18\n",
      "with 20 nodes, the mean f-score is 0.99\n",
      "True Positives: 474, False Positives: 0, False Negatives: 4\n",
      "with 40 nodes, the mean f-score is 1.00\n",
      "True Positives: 477, False Positives: 0, False Negatives: 0\n",
      "with 60 nodes, the mean f-score is 1.00\n",
      "True Positives: 478, False Positives: 0, False Negatives: 0\n",
      "with 80 nodes, the mean f-score is 1.00\n",
      "True Positives: 478, False Positives: 0, False Negatives: 0\n",
      "with 100 nodes, the mean f-score is 1.00\n",
      "True Positives: 478, False Positives: 0, False Negatives: 0\n",
      "with 150 nodes, the mean f-score is 1.00\n",
      "True Positives: 478, False Positives: 0, False Negatives: 0\n"
     ]
    }
   ],
   "source": [
    "#Let's start with a Random Forest Predictor, with 5 cross-validation sets\n",
    "#using the 2nd prediction set, let's see how many nodes are necessary for a good fit to the training set.\n",
    "\n",
    "train_f_score=[]\n",
    "j=2\n",
    "for k in [5, 10, 20, 40, 60, 80, 100, 150]:\n",
    "    f_score_values=[]\n",
    "    true_pos_scores=[]\n",
    "    false_pos_scores=[]\n",
    "    false_neg_scores=[]\n",
    "    #Cross Validation Groups\n",
    "    for i in range(5):\n",
    "        temp=list(range(5))\n",
    "        temp.remove(i)\n",
    "        #this is our set that is removed from training for validation\n",
    "        val=training_nonoble[i::5]\n",
    "        #training set consists of the other values\n",
    "        train_X=[training_nonoble[temp[0]::5], training_nonoble[temp[1]::5], training_nonoble[temp[2]::5], training_nonoble[temp[3]::5]]\n",
    "        train_X=pd.concat(train_X)\n",
    "        model=RandomForestClassifier(k, n_jobs=-1)\n",
    "        fit=model.fit(train_X[col_names], train_X['stabilityVec%s' % j])\n",
    "        rf_prediction=fit.predict(train_X[col_names])\n",
    "        temp=rf_prediction-train_X['stabilityVec%s' % j]\n",
    "        false_pos=sum(temp==1)\n",
    "        false_neg=sum(temp==-1)\n",
    "        temp=rf_prediction+train_X['stabilityVec%s' % j]\n",
    "        true_pos=sum(temp==2)\n",
    "        precision=true_pos/(true_pos+false_pos)\n",
    "        recall=true_pos/(true_pos+false_neg)\n",
    "        f_score=2*precision*recall/(precision+recall)\n",
    "        f_score_values.append(f_score)\n",
    "        true_pos_scores.append(true_pos)\n",
    "        false_pos_scores.append(false_pos)\n",
    "        false_neg_scores.append(false_neg)\n",
    "    train_f_score.append(np.mean(f_score_values))\n",
    "    print('with %s nodes, the mean f-score is %.2f' % (str(k), np.mean(f_score_values)))\n",
    "    print('True Positives: %d, False Positives: %d, False Negatives: %d' % (np.mean(true_pos_scores), \\\n",
    "            np.mean(false_pos_scores), np.mean(false_neg_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 5 nodes, the mean f-score is 0.66\n",
      "True Positives: 75, False Positives: 33, False Negatives: 44\n",
      "with 10 nodes, the mean f-score is 0.65\n",
      "True Positives: 67, False Positives: 21, False Negatives: 52\n",
      "with 20 nodes, the mean f-score is 0.67\n",
      "True Positives: 72, False Positives: 22, False Negatives: 47\n",
      "with 40 nodes, the mean f-score is 0.69\n",
      "True Positives: 74, False Positives: 22, False Negatives: 44\n",
      "with 60 nodes, the mean f-score is 0.70\n",
      "True Positives: 76, False Positives: 22, False Negatives: 43\n",
      "with 80 nodes, the mean f-score is 0.69\n",
      "True Positives: 76, False Positives: 25, False Negatives: 43\n",
      "with 100 nodes, the mean f-score is 0.70\n",
      "True Positives: 76, False Positives: 23, False Negatives: 43\n",
      "with 150 nodes, the mean f-score is 0.70\n",
      "True Positives: 76, False Positives: 22, False Negatives: 43\n"
     ]
    }
   ],
   "source": [
    "#Wow, nearly perfect fits for even the smallest set of nodes. Let's see how they perform on the test set.\n",
    "\n",
    "test_f_score=[]\n",
    "j=2\n",
    "for k in [5, 10, 20, 40, 60, 80, 100, 150]:\n",
    "    f_score_values=[]\n",
    "    true_pos_scores=[]\n",
    "    false_pos_scores=[]\n",
    "    false_neg_scores=[]\n",
    "    #Cross Validation Groups\n",
    "    for i in range(5):\n",
    "        temp=list(range(5))\n",
    "        temp.remove(i)\n",
    "        #this is our set that is removed from training for validation\n",
    "        val=training_nonoble[i::5]\n",
    "        #training set consists of the other values\n",
    "        train_X=[training_nonoble[temp[0]::5], training_nonoble[temp[1]::5], training_nonoble[temp[2]::5], training_nonoble[temp[3]::5]]\n",
    "        train_X=pd.concat(train_X)\n",
    "        model=RandomForestClassifier(k, n_jobs=-1)\n",
    "        fit=model.fit(train_X[col_names], train_X['stabilityVec%s' % j])\n",
    "        rf_prediction=fit.predict(val[col_names])\n",
    "        temp=rf_prediction-val['stabilityVec%s' % j]\n",
    "        false_pos=sum(temp==1)\n",
    "        false_neg=sum(temp==-1)\n",
    "        temp=rf_prediction+val['stabilityVec%s' % j]\n",
    "        true_pos=sum(temp==2)\n",
    "        precision=true_pos/(true_pos+false_pos)\n",
    "        recall=true_pos/(true_pos+false_neg)\n",
    "        f_score=2*precision*recall/(precision+recall)\n",
    "        f_score_values.append(f_score)\n",
    "        true_pos_scores.append(true_pos)\n",
    "        false_pos_scores.append(false_pos)\n",
    "        false_neg_scores.append(false_neg)\n",
    "    test_f_score.append(np.mean(f_score_values))\n",
    "    print('with %s nodes, the mean f-score is %.2f' % (str(k), np.mean(f_score_values)))\n",
    "    print('True Positives: %d, False Positives: %d, False Negatives: %d' % (np.mean(true_pos_scores), \\\n",
    "            np.mean(false_pos_scores), np.mean(false_neg_scores)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n38wsY/4/LPjckBdykRgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3d38e40f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the random forest seems to be doing very well with this data set, and there doesn't seem to be any evidence of\n",
    "#overfitting.\n",
    "plt.plot([5, 10, 20, 40, 60, 80, 100, 150], train_f_score, label='train')\n",
    "plt.plot([5, 10, 20, 40, 60, 80, 100, 150], test_f_score, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 5 nodes, the mean f-score is 0.91\n",
      "True Positives: 59, False Positives: 0, False Negatives: 11\n",
      "with 10 nodes, the mean f-score is 0.93\n",
      "True Positives: 61, False Positives: 0, False Negatives: 8\n",
      "with 20 nodes, the mean f-score is 0.99\n",
      "True Positives: 68, False Positives: 0, False Negatives: 1\n",
      "with 40 nodes, the mean f-score is 0.99\n",
      "True Positives: 69, False Positives: 0, False Negatives: 0\n",
      "with 60 nodes, the mean f-score is 1.00\n",
      "True Positives: 70, False Positives: 0, False Negatives: 0\n",
      "with 80 nodes, the mean f-score is 1.00\n",
      "True Positives: 70, False Positives: 0, False Negatives: 0\n",
      "with 100 nodes, the mean f-score is 1.00\n",
      "True Positives: 70, False Positives: 0, False Negatives: 0\n",
      "with 150 nodes, the mean f-score is 1.00\n",
      "True Positives: 70, False Positives: 0, False Negatives: 0\n"
     ]
    }
   ],
   "source": [
    "#I'm going to try again with a more sparsely populated vector here:\n",
    "\n",
    "train_f_score=[]\n",
    "j=1\n",
    "for k in [5, 10, 20, 40, 60, 80, 100, 150]:\n",
    "    f_score_values=[]\n",
    "    true_pos_scores=[]\n",
    "    false_pos_scores=[]\n",
    "    false_neg_scores=[]\n",
    "    #Cross Validation Groups\n",
    "    for i in range(5):\n",
    "        temp=list(range(5))\n",
    "        temp.remove(i)\n",
    "        #this is our set that is removed from training for validation\n",
    "        val=training_nonoble[i::5]\n",
    "        #training set consists of the other values\n",
    "        train_X=[training_nonoble[temp[0]::5], training_nonoble[temp[1]::5], training_nonoble[temp[2]::5], training_nonoble[temp[3]::5]]\n",
    "        train_X=pd.concat(train_X)\n",
    "        model=RandomForestClassifier(k, n_jobs=-1)\n",
    "        fit=model.fit(train_X[col_names], train_X['stabilityVec%s' % j])\n",
    "        rf_prediction=fit.predict(train_X[col_names])\n",
    "        temp=rf_prediction-train_X['stabilityVec%s' % j]\n",
    "        false_pos=sum(temp==1)\n",
    "        false_neg=sum(temp==-1)\n",
    "        temp=rf_prediction+train_X['stabilityVec%s' % j]\n",
    "        true_pos=sum(temp==2)\n",
    "        precision=true_pos/(true_pos+false_pos)\n",
    "        recall=true_pos/(true_pos+false_neg)\n",
    "        f_score=2*precision*recall/(precision+recall)\n",
    "        f_score_values.append(f_score)\n",
    "        true_pos_scores.append(true_pos)\n",
    "        false_pos_scores.append(false_pos)\n",
    "        false_neg_scores.append(false_neg)\n",
    "    train_f_score.append(np.mean(f_score_values))\n",
    "    print('with %s nodes, the mean f-score is %.2f' % (str(k), np.mean(f_score_values)))\n",
    "    print('True Positives: %d, False Positives: %d, False Negatives: %d' % (np.mean(true_pos_scores), \\\n",
    "            np.mean(false_pos_scores), np.mean(false_neg_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 5 nodes, the mean f-score is 0.31\n",
      "True Positives: 4, False Positives: 4, False Negatives: 13\n",
      "with 10 nodes, the mean f-score is 0.27\n",
      "True Positives: 3, False Positives: 1, False Negatives: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:27: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with 20 nodes, the mean f-score is nan\n",
      "True Positives: 2, False Positives: 1, False Negatives: 15\n",
      "with 40 nodes, the mean f-score is 0.29\n",
      "True Positives: 3, False Positives: 1, False Negatives: 14\n",
      "with 60 nodes, the mean f-score is 0.23\n",
      "True Positives: 2, False Positives: 1, False Negatives: 15\n",
      "with 80 nodes, the mean f-score is 0.26\n",
      "True Positives: 2, False Positives: 1, False Negatives: 14\n",
      "with 100 nodes, the mean f-score is 0.29\n",
      "True Positives: 3, False Positives: 0, False Negatives: 14\n",
      "with 150 nodes, the mean f-score is 0.26\n",
      "True Positives: 2, False Positives: 1, False Negatives: 14\n"
     ]
    }
   ],
   "source": [
    "#Wow, nearly perfect fits for even the smallest set of nodes. Let's see how they perform on the test set.\n",
    "\n",
    "test_f_score=[]\n",
    "j=1\n",
    "for k in [5, 10, 20, 40, 60, 80, 100, 150]:\n",
    "    f_score_values=[]\n",
    "    true_pos_scores=[]\n",
    "    false_pos_scores=[]\n",
    "    false_neg_scores=[]\n",
    "    #Cross Validation Groups\n",
    "    for i in range(5):\n",
    "        temp=list(range(5))\n",
    "        temp.remove(i)\n",
    "        #this is our set that is removed from training for validation\n",
    "        val=training_nonoble[i::5]\n",
    "        #training set consists of the other values\n",
    "        train_X=[training_nonoble[temp[0]::5], training_nonoble[temp[1]::5], training_nonoble[temp[2]::5], training_nonoble[temp[3]::5]]\n",
    "        train_X=pd.concat(train_X)\n",
    "        model=RandomForestClassifier(k, n_jobs=-1)\n",
    "        fit=model.fit(train_X[col_names], train_X['stabilityVec%s' % j])\n",
    "        rf_prediction=fit.predict(val[col_names])\n",
    "        temp=rf_prediction-val['stabilityVec%s' % j]\n",
    "        false_pos=sum(temp==1)\n",
    "        false_neg=sum(temp==-1)\n",
    "        temp=rf_prediction+val['stabilityVec%s' % j]\n",
    "        true_pos=sum(temp==2)\n",
    "        precision=true_pos/(true_pos+false_pos)\n",
    "        recall=true_pos/(true_pos+false_neg)\n",
    "        f_score=2*precision*recall/(precision+recall)\n",
    "        f_score_values.append(f_score)\n",
    "        true_pos_scores.append(true_pos)\n",
    "        false_pos_scores.append(false_pos)\n",
    "        false_neg_scores.append(false_neg)\n",
    "    test_f_score.append(np.mean(f_score_values))\n",
    "    print('with %s nodes, the mean f-score is %.2f' % (str(k), np.mean(f_score_values)))\n",
    "    print('True Positives: %d, False Positives: %d, False Negatives: %d' % (np.mean(true_pos_scores), \\\n",
    "            np.mean(false_pos_scores), np.mean(false_neg_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwl1EJIYU7iIiMaRwFxGJof8PqiG6X/nEDskAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3d0fe2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Again, this is a pretty good performance, with no evidence of overfitting.\n",
    "plt.plot([5, 10, 20, 40, 60, 80, 100, 150], train_f_score, label='train')\n",
    "plt.plot([5, 10, 20, 40, 60, 80, 100, 150], test_f_score, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for vector 0, the mean f-score is 0.32\n",
      "True Positives: 2, False Positives: 1, False Negatives: 7\n",
      "for vector 1, the mean f-score is 0.22\n",
      "True Positives: 2, False Positives: 0, False Negatives: 15\n",
      "for vector 2, the mean f-score is 0.69\n",
      "True Positives: 75, False Positives: 22, False Negatives: 44\n",
      "for vector 3, the mean f-score is 0.39\n",
      "True Positives: 9, False Positives: 3, False Negatives: 25\n",
      "for vector 4, the mean f-score is 0.70\n",
      "True Positives: 72, False Positives: 18, False Negatives: 44\n",
      "for vector 5, the mean f-score is 0.40\n",
      "True Positives: 10, False Positives: 3, False Negatives: 26\n",
      "for vector 6, the mean f-score is 0.48\n",
      "True Positives: 26, False Positives: 11, False Negatives: 45\n",
      "for vector 7, the mean f-score is 0.56\n",
      "True Positives: 35, False Positives: 12, False Negatives: 42\n",
      "for vector 8, the mean f-score is 0.41\n",
      "True Positives: 3, False Positives: 1, False Negatives: 8\n"
     ]
    }
   ],
   "source": [
    "#Let's go for 100 nodes and loop over all 9 of the vectors.\n",
    "for j in range(9):\n",
    "    f_score_values=[]\n",
    "    true_pos_scores=[]\n",
    "    false_pos_scores=[]\n",
    "    false_neg_scores=[]\n",
    "    #Cross Validation Groups\n",
    "    for i in range(5):\n",
    "        temp=list(range(5))\n",
    "        temp.remove(i)\n",
    "        #this is our set that is removed from training for validation\n",
    "        val=training_nonoble[i::5]\n",
    "        #training set consists of the other values\n",
    "        train_X=[training_nonoble[temp[0]::5], training_nonoble[temp[1]::5], training_nonoble[temp[2]::5], training_nonoble[temp[3]::5]]\n",
    "        train_X=pd.concat(train_X)\n",
    "        model=RandomForestClassifier(100, n_jobs=-1)\n",
    "        fit=model.fit(train_X[col_names], train_X['stabilityVec%s' % j])\n",
    "        rf_prediction=fit.predict(val[col_names])\n",
    "        temp=rf_prediction-val['stabilityVec%s' % j]\n",
    "        false_pos=sum(temp==1)\n",
    "        false_neg=sum(temp==-1)\n",
    "        temp=rf_prediction+val['stabilityVec%s' % j]\n",
    "        true_pos=sum(temp==2)\n",
    "        precision=true_pos/(true_pos+false_pos)\n",
    "        recall=true_pos/(true_pos+false_neg)\n",
    "        f_score=2*precision*recall/(precision+recall)\n",
    "        if np.isnan(f_score): f_score=0\n",
    "        f_score_values.append(f_score)\n",
    "        true_pos_scores.append(true_pos)\n",
    "        false_pos_scores.append(false_pos)\n",
    "        false_neg_scores.append(false_neg)\n",
    "    print('for vector %s, the mean f-score is %.2f' % (str(j), np.mean(f_score_values)))\n",
    "    print('True Positives: %d, False Positives: %d, False Negatives: %d' % (np.mean(true_pos_scores), \\\n",
    "            np.mean(false_pos_scores), np.mean(false_neg_scores)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for vector 0, the mean f-score is 0.29\n",
      "True Positives: 2, False Positives: 4, False Negatives: 7\n",
      "for vector 1, the mean f-score is 0.34\n",
      "True Positives: 4, False Positives: 2, False Negatives: 13\n",
      "for vector 2, the mean f-score is 0.67\n",
      "True Positives: 70, False Positives: 21, False Negatives: 49\n",
      "for vector 3, the mean f-score is 0.33\n",
      "True Positives: 8, False Positives: 6, False Negatives: 26\n",
      "for vector 4, the mean f-score is 0.66\n",
      "True Positives: 67, False Positives: 21, False Negatives: 49\n",
      "for vector 5, the mean f-score is 0.37\n",
      "True Positives: 9, False Positives: 5, False Negatives: 27\n",
      "for vector 6, the mean f-score is 0.46\n",
      "True Positives: 25, False Positives: 10, False Negatives: 47\n",
      "for vector 7, the mean f-score is 0.52\n",
      "True Positives: 33, False Positives: 14, False Negatives: 45\n",
      "for vector 8, the mean f-score is 0.37\n",
      "True Positives: 3, False Positives: 5, False Negatives: 8\n"
     ]
    }
   ],
   "source": [
    "#Not bad! Now, let's give gradient boosting a try.\n",
    "for j in range(9):\n",
    "    f_score_values=[]\n",
    "    true_pos_scores=[]\n",
    "    false_pos_scores=[]\n",
    "    false_neg_scores=[]\n",
    "    #Cross Validation Groups\n",
    "    for i in range(5):\n",
    "        temp=list(range(5))\n",
    "        temp.remove(i)\n",
    "        #this is our set that is removed from training for validation\n",
    "        val=training_nonoble[i::5]\n",
    "        #training set consists of the other values\n",
    "        train_X=[training_nonoble[temp[0]::5], training_nonoble[temp[1]::5], training_nonoble[temp[2]::5], training_nonoble[temp[3]::5]]\n",
    "        train_X=pd.concat(train_X)\n",
    "        model=GradientBoostingClassifier()\n",
    "        fit=model.fit(train_X[col_names], train_X['stabilityVec%s' % j])\n",
    "        gb_prediction=fit.predict(val[col_names])\n",
    "        temp=gb_prediction-val['stabilityVec%s' % j]\n",
    "        false_pos=sum(temp==1)\n",
    "        false_neg=sum(temp==-1)\n",
    "        temp=gb_prediction+val['stabilityVec%s' % j]\n",
    "        true_pos=sum(temp==2)\n",
    "        precision=true_pos/(true_pos+false_pos)\n",
    "        recall=true_pos/(true_pos+false_neg)\n",
    "        f_score=2*precision*recall/(precision+recall)\n",
    "        if np.isnan(f_score): f_score=0\n",
    "        f_score_values.append(f_score)\n",
    "        true_pos_scores.append(true_pos)\n",
    "        false_pos_scores.append(false_pos)\n",
    "        false_neg_scores.append(false_neg)\n",
    "    print('for vector %s, the mean f-score is %.2f' % (str(j), np.mean(f_score_values)))\n",
    "    print('True Positives: %d, False Positives: %d, False Negatives: %d' % (np.mean(true_pos_scores), \\\n",
    "            np.mean(false_pos_scores), np.mean(false_neg_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set vector 0 prediction ratio is 0.02\n",
      "Test set vector 0 prediction ratio is 0.05\n",
      "Training set vector 1 prediction ratio is 0.03\n",
      "Test set vector 1 prediction ratio is 0.06\n",
      "Training set vector 2 prediction ratio is 0.21\n",
      "Test set vector 2 prediction ratio is 0.20\n",
      "Training set vector 3 prediction ratio is 0.05\n",
      "Test set vector 3 prediction ratio is 0.06\n",
      "Training set vector 4 prediction ratio is 0.21\n",
      "Test set vector 4 prediction ratio is 0.24\n",
      "Training set vector 5 prediction ratio is 0.05\n",
      "Test set vector 5 prediction ratio is 0.04\n",
      "Training set vector 6 prediction ratio is 0.10\n",
      "Test set vector 6 prediction ratio is 0.12\n",
      "Training set vector 7 prediction ratio is 0.12\n",
      "Test set vector 7 prediction ratio is 0.11\n",
      "Training set vector 8 prediction ratio is 0.03\n",
      "Test set vector 8 prediction ratio is 0.08\n"
     ]
    }
   ],
   "source": [
    "#The two are pretty similar, which makes sense. I'll go ahead and make a prediction on the test dataset, though \n",
    "#I am still waiting on some results for neural nets before I decide which to ultimately use for my submission.\n",
    "\n",
    "#Test data was processed identically to the training data and normalized the same way, removing noble gases and\n",
    "#then dividing by the max value of each column.\n",
    "\n",
    "#Sanity check ratios are included.\n",
    "\n",
    "for j in range(9):\n",
    "    model=GradientBoostingClassifier()\n",
    "    fit=model.fit(training_nonoble[col_names], training_nonoble['stabilityVec%s' % j])\n",
    "    gb_prediction=fit.predict(training_nonoble[col_names])\n",
    "    print('Training set vector %s prediction ratio is %.2f' %(j, np.sum(gb_prediction)/len(gb_prediction)))\n",
    "    gb_prediction=fit.predict(test[col_names])\n",
    "    print('Test set vector %s prediction ratio is %.2f' %(j, np.sum(gb_prediction)/len(gb_prediction)))\n",
    "    test['stabilityVec%s' % j] = gb_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Those numbers look reasonable.\n",
    "#Setting noble gas predictions to zero\n",
    "for i in range(len(test)):\n",
    "    if test['formulaA'][i] in ['Ne', 'Ar', 'Kr', 'He', 'Xe']:\n",
    "        for j in range(9):\n",
    "            test['stabilityVec%s' % j][i]=0\n",
    "    \n",
    "    if test['formulaB'][i] in ['Ne', 'Ar', 'Kr', 'He', 'Xe']:\n",
    "        for j in range(9):\n",
    "            test['stabilityVec%s' % j][i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/nick/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#reformat the data into a .1 float string of values\n",
    "test['stabilityVec'][i]='[1.0,'\n",
    "for i in range(len(test)):\n",
    "    for j in range(9):\n",
    "        test['stabilityVec'][i]+='%.1f,' % test['stabilityVec%s' % j][i]\n",
    "    test['stabilityVec'][i]+='1.0]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "1     [1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "2     [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "3     [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "4     [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "5     [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "6     [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "7     [1.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0]\n",
       "8     [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "9     [1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0]\n",
       "10    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "11    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,1.0]\n",
       "12    [1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0]\n",
       "13    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "14    [1.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,1.0]\n",
       "15    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "16    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "17    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "18    [1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,1.0]\n",
       "19    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "20    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "21    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0]\n",
       "22    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0]\n",
       "23    [1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,1.0]\n",
       "24    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "Name: stabilityVec, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['stabilityVec'].head(n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Hope its reasonably right! Time to save the values\n",
    "test.to_csv('test_data_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "1    [1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "2    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "3    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "4    [1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n",
       "Name: stabilityVec, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double Check\n",
    "temp=pd.read_csv('test_data_output.csv')\n",
    "temp['stabilityVec'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Looks OK! We'll see what happens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
